---
title: "Rstudio in Data Science and Paper Writing"
author: "Gáspár Jékely <br> Centre for Organismal Studies, Heidelberg University"
format:
  revealjs: 
    theme: [default, custom.scss]
    slide-number: true
    code-fold: false
    code-summary: "Code"
    chalkboard: 
      buttons: false
    preview-links: auto
scrollable: true
---

## Course program

<br>

- **Part 1**: Why open science? 
\

- **Part 2**: Project management, data import, tidy data
\

- **Part 3**: Plotting with ggplot
\

- **Part 4**: Assembly of figures
\

- **Part 5**: Manuscript writing, tables, references, data and figure embedding
\

- **Part 6**: GitHub, collaboration, sharing, version control

```{r eval=TRUE, echo=FALSE}
source("../analysis/scripts/packages_and_functions.R")
```

## Resources

<br><br>

- The [Tidyverse Cookbook](https://rstudio-education.github.io/tidyverse-cookbook/) (edited by Garrett Grolemund)\

https://rstudio-education.github.io/tidyverse-cookbook/

## Part 1 - Why do we need open science

- Reproducibility crisis
- Only a small fraction of research data is available
- An even smaller fraction of code is available (physicists are notoriously bad in sharing)
- Open access, if exists, is very expensive and maintains the profit of legacy publishers
- Scholarly literature is antiquated, dysfunctional and rewards prestige/hype over quality and integrity
- Scholarly workflows use non-professional, error-prone, closed-source software (MS, Adobe, Prism etc.) that makes sharing, integration, automation and collaboration difficult
- The final product of years of research is often only a single pdf file (1990s tech) behind a paywall
- Data, code and text are not searchable, reuseable, discoverable, shareable

## Most source data collected by scientists are not available

<br>

![](images/Data_publication_Pyramide.png){height=450}

## Most scientists use software developed for accounting {transition="fade" transition-speed="fast"}

![](images/Scientists_rename_genes.png)
[theverge.com](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates)

- the symbol MARCH1 has now become MARCHF1, while SEPT1 has become SEPTIN1, and so on

<br>

## Gene name errors are widespread in the scientific literature

<br><br>

![](images/13059_2016_1044_Fig1_HTML.webp)


::: aside
[Ziemann et al. (2016)](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7)
:::

## Code is very often not shared or not shared stably

- *We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science ... We found that we were able to obtain artifacts from 44% of our sample and were able to reproduce the findings for 26%.*

::: {.incremental}
- "When you approach a PI for the source codes and raw data, you better explain who you are, whom you work for, why you need the data and what you are going to do with it."

- "I have to say that this is a very unusual request without any explanation! Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation."

- "The data files remains our property and are not deposited for free access. Please, let me know the purpose you want to get the file and we will see how we can help you."

- "We do not typically share our internal data or code with people outside our collaboration."

:::

![](images/Stodden_PNAS.png){.absolute top="480" left="300" height="200"}

::: aside
[Stodden et al. (2018) ](https://doi.org/10.1073/pnas.1708290115)
:::

## Current state of scholarly digital infrastructure and knowhow

<img src=https://media1.tenor.com/images/f6362876996697b6a6f554b2ac3d3013/tenor.gif?itemid=10488408 width=160>


## What this course is about: what you can do to be open

- tools and approaches for transparent and open publishing
- a paper is not only text and figures, but also data and code
- all should be shared for reproducibility and openness
- otherwise it is not really 'published'
- we will use Rstudio to learn a comprehensive paper-writing pipeline
- code, tabulated data, figures, text, references, supplements all in one place
- collaborative working and sharing via GitHub (or other public repository)
- the figures are linked to their underlying data and code to generate them
- efficient version control
- faster, more transparent and reproducible workflow
- no software license is needed (no MS, no Adobe, no Matlab)
- once you master the approach I advocate, you don't want to go back...

## Part 2 - Packages, project management, data import, tidy data

<br>

- some rules on files, folders
- R projects
- installing and loading packages
- project templates
- importing various types of datasets
- principles of tidy data, tidying of messy datasets

## Go to GitHub and fork my repository

<br><br>

- do you have a GitHub account? 
- navigate to: https://github.com/JekelyLab/RStudio_paper_writing_course
- fork the repository to your GitHub (if you have an account already)
- go to RStudio -> New Project -> Git -> your repo's address (or my address)
- select local dir and download the project with all directories to your computer
- let's check the project
- you can rename the .Rproject file to 'my favourite file name'
- open /analysis/scripts/Course_exercises.R

## Rule nr. 1 -- relative working directories

<br>

```{r, eval=FALSE, echo=TRUE}
#| code-fold: false
getwd()
```


-   Never use absolute paths in your scripts, because they hinder sharing: no one else will have exactly the same directory configuration as you.

- Do not use setwd() to set your working dir

## Use R projects (.Rproj)

<br>

-   Keep all files associated with a project together — input data, R scripts, analytical results, figures. This is such a wise and common practice that RStudio has built-in support for this via **Rprojects**.

-   If you create a new Rproject, your working dir will in general be where you save the new project

-   Whenever you refer to a file with a relative path it will look for it in your working dir.

- in case you used setwd() in a script (you should not) you can find your Rproject directory with here()

```{r, eval=TRUE, echo=TRUE}
here::here()

#test, but you should not do this
setwd("~")
getwd()

#get back to Rproj dir
setwd(here::here())
getwd()
# all good again
```

## Use R projects (.Rproj)

<br>

- list files in your working dir 

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
list.files()
```


## Project management

<br><br><br>

* Use folders relative to your main .Rproject file (e.g. My_next_report.Rproject)

* Use a consistent directory structure to store code, data, text, figures, supplements, etc.

* Can be ensured if you always use the same project template

* Check the folder structure in the downloaded project template

## Installing packages

* install the **tidyverse** package
```{r, eval=FALSE, echo=TRUE}
#| code-fold: false
install.packages("tidyverse")
```


- then load the package
```{r, eval=FALSE, echo=TRUE}
#| code-fold: false
library(tidyverse)
library(png)
```

## You can source packages and functions from one file

<br><br>

* open the R script analysis/scripts/Course_exercises.R with the example code

* source several packages and functions, listed in one file consistently across scripts

```{r eval=FALSE, echo=TRUE, tidy=FALSE, fig.height=5}
#| code-fold: false
source("../analysis/scripts/packages_and_functions.R")
```

## General good practice -- avoid spaces in file names 

:::{.incremental}

<br>
```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
list.files("../analysis/data")
```

<br>
```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
readxl::read_excel("../analysis/data/data - José - March 2024.xlsx")
```
:::

## Save and share your computer environment and packages

```{r echo=TRUE, eval=TRUE}
#save session info and Rstudio version info for reproducibility
sessionInfo()
writeLines(capture.output(sessionInfo()), "sessionInfo.txt")
```



## File import and saving -- rio: A Swiss-Army Knife for Data I/O  

- import xlsx, csv, tsv and many other formats with the same command

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
data_Jose <- rio::import("../analysis/data/data - José - March 2024.xlsx")
```

- export as csv

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
rio::export(data_Jose, "../analysis/data/data_Jose_March2024.csv")
```

- export as compressed csv

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
export(data_Jose, "../analysis/data/data_Jose_March2024.csv.zip")
```

- convert file formats

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false
rio::convert("../analysis/data/data - José - March 2024.xlsx",
"../analysis/data/data_Jose_March2024.csv")
```

::: aside
[Documentation of the rio package](http://gesistsa.github.io/rio/)
:::


## Read and preview data 1

```{r}
#| eval=TRUE, echo=TRUE
data_Jose <- readxl::read_excel("../analysis/data/data - José - March 2024.xlsx")
head(data_Jose)
glimpse(data_Jose)
str(data_Jose)
summary(data_Jose)
```


## Your workspace in R

- Recreate, rather than save workspace, save your coda and data, not workspace <br>

<img src=images/rstudio-workspace.png width=60%>

## Read and preview data 2

```{r}
#| eval=TRUE, echo=TRUE
data_Ashwini <- readxl::read_excel("../analysis/data/24_01_22qpcr_1 - ash pal.xlsx")
head(data_Ashwini)
glimpse(data_Ashwini)
str(data_Ashwini)
summary(data_Ashwini)
```

## Tidy data - definitions

from https://r4ds.hadley.nz/data-visualize

- A **variable** is a quantity, quality, or property that you can measure
- A **value** is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.
- An **observation** is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We’ll sometimes refer to an observation as a data point.

## Tidy data - definitions

* Tabular data is a set of values, each associated with a variable and an observation. 

* Tabular data is tidy if each value is placed in its own “cell”, each variable in its own column, and each observation in its own row.

* “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

__There are three interrelated rules which make a dataset tidy:__

* Each variable must have its own column.
* Each observation must have its own row.
* Each value must have its own cell.

<img src=images/tidy-1.png width=60%>

## Tidy data - an example tidy dataset

```{r, echo=TRUE}
knitr::kable(head(iris), format = 'html')
```


## Tibbles = tabular data in tidy format

```{r}
#| eval=FALSE, echo=TRUE
vignette("tibble")

```

- Tibbles are a modern take on data frames. 
- They keep the features that have stood the test of time, and drop the features that used to be convenient but are now frustrating.
- Tibbles encapsulate best practices for data frames.
- tibble() It never uses row.names().

## Tidy data -- __Why should I care?__

<br>

- after reading your data, you should always try to convert them into a tibble
- downstream analyses (plotting, mutating, sharing etc.) will be a lot easier
- data coming from other software, collaborators etc. are often 'messy'
- it is worth investing the time in tidying the data first
- sometimes it is tricky, as we will see...

## Let's try to fix a messy dataset...

```{r}
#| eval=TRUE, echo=TRUE
Gene <- c(rep("Nanog", 15), rep("oct4", 15), rep("sox2", 15),
  rep("Nestin", 15), rep("pax6", 15), rep("Foxg1", 15),
  rep("GAPDH", 15))
Gene

data_Ashwini$Gene <- Gene
head(data_Ashwini)
```


## Select only relevant columns and clean up names...

```{r}

#| eval=TRUE, echo=TRUE
data_Ashwini_sel <- data_Ashwini %>%
  select(1:6) %>%
  janitor::clean_names()
data_Ashwini_sel
```

## Add mean and SD columns with group_by() and mutate()

```{r}
#| eval=TRUE, echo=TRUE
data_Ashwini_sel_M_SD <- data_Ashwini_sel %>%
  group_by(gene) %>%
  mutate(mean2dct = mean(x2_dct)) %>%
  mutate(sd2dct = sd(x2_dct))
data_Ashwini_sel_M_SD
```


## Change data type...

```{r}
#| eval=TRUE, echo=TRUE
data_Ashwini_sel_M_SD <- data_Ashwini_sel_M_SD %>%
  mutate(ct_value = as.double(ct_value))
data_Ashwini_sel_M_SD
```

## Pivoting 

- Tidying messy data is hard and requires parctice
- Read more here: https://r4ds.had.co.nz/tibbles.html

```{r}
#| eval=TRUE, echo=TRUE
data_Syn <- read_csv("../analysis/data/a-Syn-Data.csv")
data_Syn
# rename
data_Syn_clean <- data_Syn  %>%
  rename_with(~ gsub("_", "-", .x, fixed = TRUE)) %>%
  rename_with(~ gsub("...", "_", .x, fixed = TRUE))

tb_syn <- data_Syn_clean |>
  pivot_longer(matches("aSyn"), 
               names_to = c("condition", "sample"), 
               names_sep = "_",
               values_to = "fluorescence")
 tb_syn
```

## Part 3 - data plotting with ggplot

<br>

- once your data have been tidied up, plotting is a lot easier
- use ggplot2 and a tibble as input
- ggplot2 is part of tidyverse and loads when you load tidyverse
- very versatile and extendable data visualisation package
- as input, you need a tibble (or a data.frame)
- supply data, define aesthetic mapping, add layers, define axes, plot theme etc.
- use the same theme (font size, line width etc.) across all figures in a project/paper/thesis
- statistical tests
- saving plots and source data

![](images/ggplot2-2177292224.png)

## Aesthetics, plot types and themes

* need to define 'aesthetics', which variable goes to x, y axes, to colour, size, line thickness etc.
* need to select plot type (geom_...  boxplot, line, points etc.)
* need to define 'theme' such as axis thickness, fonts, ticks, borders etc.

```{r eval = TRUE, echo = TRUE, fig.height = 4}

iris %>%  
  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  geom_boxplot(notch = TRUE) +
  theme_minimal()

```

## Faceting

<br>

- Faceting means spreading the data across different panels

- Need to define 'facets', a set of variables or expressions quoted by vars() defining faceting groups

```{r eval = TRUE, echo = TRUE, fig.height = 4}
iris %>%  
  ggplot(aes(
    x = Petal.Length, y = Sepal.Width, 
    color = Species, size = Sepal.Width, shape = Species) 
    ) +
  geom_point(alpha = 0.5) +
  facet_wrap(vars(Species))
```



## Resources

<br>
https://ggplot2.tidyverse.org/

https://r4ds.hadley.nz/

- ggplot cheat sheet
https://rstudio.github.io/cheatsheets/data-visualization.pdf

![](images/ggplot2-2177292224.png)

## Plot data - Jose

```{r}
#| eval=TRUE, echo=TRUE

plot_Jose1 <- data_Jose %>%
  ggplot(aes(x = genotype, y = length, fill = factor(Treatment, level=c('Control', 'ABA', 'Sulfate')), na.rm = TRUE)) +
  geom_boxplot() +
  theme_minimal() +
  scale_fill_manual(values = c("#D55E00", "#E69F00", "#cccccc")) +
  guides(fill = guide_legend(title = "Treatment")) 

plot_Jose1  
 
```

```{r, eval=TRUE, echo=TRUE}
#| code-fold: false

library(ggplot2)
plot_Jose2 <- data_Jose %>%
  ggplot(aes(x = genotype, y = length, fill = factor(Treatment, level=c('Control', 'ABA', 'Sulfate')), na.rm = TRUE)) +
  geom_violin() +
  geom_point( position=position_jitterdodge(jitter.width = 0.3, dodge.width = 0.9), alpha = 0.5, size = 0.4) +
  scale_fill_manual(values = c("#D55E00", "#E69F00", "#aaaaaa", "#dddddd")) +
  guides(fill = guide_legend(title = "Treatment")) 
plot_Jose2
```

## A note on languages

- you can also use python, bash etc in code blocks

```{python, echo=TRUE}
import matplotlib
print(matplotlib.__version__)
```

```{python, echo=TRUE}
#| label: fig-polar
#| fig-cap: "A line plot on a polar axis"

import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```

## Plot data

```{r}
#| eval=TRUE, echo=TRUE
data_Ashwini_sel_M_SD %>%
  group_by(gene) %>%
  ggplot(aes(x = days, y = dt_ct, fill = gene )) +
  geom_boxplot()

data_Ashwini_sel_M_SD %>%
  ggplot(aes(x = ct_value)) +
  geom_histogram()

```
## Plot data

```{r}
#| eval=TRUE, echo=TRUE
plot_Ashwini_ct <- data_Ashwini_sel_M_SD %>%
  group_by(gene) %>%
  ggplot(aes(x = gene, y = ct_value, fill = gene )) +
  geom_boxplot(na.rm = TRUE) 
plot_Ashwini_ct

```

## Plot the Synuclein data

```{r eval = TRUE, echo = TRUE, fig.height = 5}
plot_syn <- tb_syn %>%
  ggplot(aes(x = Time, y = fluorescence, color = condition)) +
  geom_smooth(method = 'loess') +
  theme_minimal()
plot_syn

```


## Read and preview data 3

```{r}
#| eval=TRUE, echo=TRUE
data_Anchel <- readxl::read_excel("../analysis/data/240323 CIN Exp278 reporter assay - Anchel.xlsx")
head(data_Anchel)
glimpse(data_Anchel)
str(data_Anchel)
summary(data_Anchel)
```

# Add significance values of stats

```{r}
#| eval=TRUE, echo=TRUE

plot_Ashwini_ct +
  stat_compare_means(
    aes(label = after_stat(p.format)),
    method = "wilcox.test",
    #ref.group = "Foxg1"
    comparisons = list( c("GAPDH", "Nanog"), c("GAPDH", "oct4"), c("GAPDH", "pax6") )
    )
```


## Save tidy data as source data for the plot/figure/paper

```{r}
#| echo=TRUE, eval=TRUE
write_csv2(data_Ashwini_sel_M_SD, "../manuscript/source_data/FigureX_Ashwini_source_data.csv")
# check
read_csv2("../manuscript/source_data/data_Ashwini_sel_M_SD.csv")
```


## Format plots with predefined complete ggplot2 themes

::: columns
::: {.column width=50%}
```{r}
#| echo=TRUE, eval=TRUE
plot_Jose1 +
  theme_dark()
plot_Jose1 +
  theme_bw()
plot_Jose1 +
  theme_linedraw()
```
:::
::: {.column width=50%}
```{r}
#| echo=TRUE, eval=TRUE
plot_Jose2 +
  theme_classic()
plot_Jose2 +
  theme_minimal()
plot_Jose2 +
  theme_light()
```
:::
:::


## Format plots with a common custom theme()

- Themes are a powerful way to customize the non-data components of your plots: i.e. titles, labels, fonts, background, gridlines, and legends.



```{r}
#| echo=TRUE, eval=TRUE
args(theme)
```


## Format plots with a common custom theme()

```{r}
#| echo=TRUE, eval=TRUE
theme_plots <- theme_minimal() +
  theme(
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.key.size = unit(7, "mm")
  )

plot_Ashwini_ct <- plot_Ashwini_ct +
  theme_plots
plot_Ashwini_ct

plot_Jose1 <- plot_Jose1 +
  theme_plots
plot_Jose1

plot_Jose2 <- plot_Jose2 +
  theme_plots
plot_Jose2

plot_syn <- plot_syn +
  theme_plots
plot_syn
```

## Optional - save plots


```{r}
#| echo=TRUE, eval=TRUE
ggsave( "../analysis/pictures/plot_Jose1a.png",
  limitsize = FALSE,
  units = c("px"), plot_Jose1,
  width = 2400, height = 1400, bg = "white"
)

# save in a different size
ggsave( "../analysis/pictures/plot_Jose1b.png",
  limitsize = FALSE,
  units = c("px"), plot_Jose2,
  width = 2400, height = 2000, bg = "white"
)


ggsave(
  "../analysis/pictures/synuclein_plot.png", plot_syn, 
  bg = "white"
  )

```

## Part 4 - Assembly of figures with cowplot and patchwork

```{r}
#| echo=TRUE, eval=TRUE

img1 <- readPNG("../analysis/pictures/plot_Jose1a.png")
img2 <- readPNG("../analysis/pictures/plot_Jose1b.png")
panel_JoseA <- ggdraw() + draw_image(img1)
panel_JoseB <- ggdraw() + draw_image(img2)

#define layout with textual representation
layout <- "
AB
CD"

#assemble multipanel figure based on layout
Figure_Jose <- panel_JoseA + panel_JoseB + plot_Jose1 + plot_Jose2 +
  plot_layout(design = layout, heights = c(1, 1, 1, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png and pdf
ggsave(
  "../manuscript/figures/Figure_Jose.png", limitsize = FALSE, 
  units = c("px"), Figure_Jose, width = 4000, height = 2000, bg = "white"
  )
ggsave(
  "../manuscript/figures/Figure_Jose.pdf", limitsize = FALSE, 
  units = c("px"), Figure_Jose, width = 3000, height = 1600
  )
```

```{r}
#| echo=FALSE, eval=TRUE

image_read("../manuscript/figures/Figure_Jose.png")
```



## Annotating a ggplot object

```{r}
#| echo=TRUE, eval=TRUE

plot_syn_ann <- plot_syn +
  annotate("segment", x = 20, xend = 50, y = 1, yend = 1, linewidth = 1)+
  annotate("text", x = 34, y = 300, label = "30 sec", size = 3)
plot_syn_ann
```

## Annotating an image

```{r}
#| echo=TRUE, eval=TRUE

#read images
img_INNOS <- magick::image_read("../analysis/pictures/INNOS_synapses.png")

#define arrow endpoints 
arrow <- data.frame(x1 = 0.95, x2 = 0.95, y1 = 0.8, y2 = 0.9)

#add text labels
panel_INNOS <- ggdraw() + 
  draw_image(img_INNOS) +
  draw_label("INNOS", x = 0.3, y = 0.99, size = 10) +
  draw_label("NS plexus", x = 0.485, y = 0.59, size = 8) +
  draw_label("outgoing", x = 0.9, y = 0.45, size = 10, color='#E69F00') +
  draw_label("incoming", x = 0.89, y = 0.5, size = 10, color='#0072B2') +
  draw_label("D", x = 0.95, y = 0.93, size = 6) +
  draw_label("V", x = 0.95, y = 0.77, size = 6) +
  draw_label("*", x = 0.5, y = 0.29, color='black',size = 18,fontface='plain') +
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = arrow, 
               arrow = arrow(ends = "both", type = "closed", length = unit(0.1,"cm")),
               lineend = "butt",
               linejoin = "mitre",
               arrow.fill = "black", size = 0.2)
```

## Annotating an image

```{r}
#| echo=TRUE, eval=TRUE
#define layout
layout <- "AB"

#assemble multipanel figure based on layout
Figure_INNOS <- plot_syn_ann + panel_INNOS +
  plot_layout(design = layout, widths = c(2, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_INNOS.png", limitsize = FALSE,
  units = c("px"), Figure_INNOS, 
  width = 3000, height = 1000,
  bg = "white"
  )

#save figure as pdf
ggsave(
  "../manuscript/figures/Figure_IHC.pdf", limitsize = FALSE, 
  units = c("px"), Figure_INNOS, width = 3000, height = 1000
  )
```

```{r}
#| echo=FALSE, eval=TRUE

image_read("../manuscript/figures/Figure_IHC.png")
```


## Adding consistent scale bars


- you could add the scale bar directly on the image e.g., in ImageJ, however..
- your scale bars may be misaligned and of varying thickness
- you can use cowplot::draw_line instead
- the x positions of the start and end of the line are defined as % of the panel width
- if you know the width of the image (e.g., can add it to file name), it is easy to calculate the size of the scale bar

```{r, eval=TRUE, echo=TRUE}
#| code-fold: true

#read images and make annotated panel
panel_NOS2d_HCR <- ggdraw() + draw_image(readPNG("../analysis/pictures/HCR-IHC_51_AP_NOS_actub_56um.png")) +
  draw_label("in situ HCR", x = 0.3, y = 0.99, size = 10) +
  draw_label("NOS", x = 0.12, y = 0.9, color="magenta", size = 11, fontface="italic") +
  draw_label("acTub", x = 0.36, y = 0.9, color="green", size = 11, fontface="plain") +
  draw_line(x = c(0.1, 0.46), y = c(0.08, 0.08), color = "white", size = 0.5) +
  draw_label(expression(paste("20 ", mu, " m")), x = 0.28, y = 0.11, color = "white", size = 8)
  

panel_NIT_HCR <- ggdraw() + draw_image(readPNG("../analysis/pictures/HCR_72_AP_NIT_94um.png")) +
  draw_label("transgene + IHC", x = 0.38, y = 0.99, size = 10) +
  draw_label("NOSp::palmi-3xHA", x = 0.34, y = 0.9, color="magenta", size = 10, fontface="plain") +
  draw_label("acTub", x = 0.8, y = 0.9, color="green", size = 10, fontface="plain") +
  draw_line(x = c(0.1, 0.31), y = c(0.08, 0.08), color = "white", size = 0.5) 
```

```{r}
#| echo=TRUE, eval=TRUE

#introduce gap in layout
layout <- "A#B"

#assemble multipanel figure based on layout
Figure_scalebars <- panel_NOS2d_HCR + panel_NIT_HCR +
  plot_layout(design = layout, widths = c(1, 0.03, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_scalebars.png",
  units = c("px"), Figure_scalebars, 
  width = 1700, height = 940, bg = "white"
  )

image_read("../manuscript/figures/Figure_scalebars.png")
image_read("../manuscript/figures/Figure_scalebars.png")
```

## Reading tif files, parsing metadata like image scale

```{r}
#| echo=TRUE, eval=TRUE
#| 
img_tif <- magick::image_read("../analysis/pictures/INNOS_synapses.tif")
img_scale <- image_info(img_tif)$width/as.numeric(str_split(image_info(img_tif)$density, "x")[[1]][1])
img_scale #not precise

# alternatively use ijtiff
library(ijtiff)
img_tif_ij <- ijtiff::read_tags("../analysis/pictures/INNOS_synapses.tif")
img_scale <- img_tif_ij$frame1$width/img_tif_ij$frame1$x_resolution
img_scale

panel_INNOS_tif <- ggdraw() + draw_image(img_tif)

Figure_INNOS_with_tif <- plot_syn_ann + panel_INNOS_tif +
  plot_layout(design = layout, widths = c(2, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_INNOS_with_tif.png", limitsize = FALSE,
  units = c("px"), Figure_INNOS_with_tif, 
  width = 3000, height = 1000, bg = "white"
  )
```

```{r}
#| echo=FALSE, eval=TRUE

image_read("../manuscript/figures/Figure_INNOS_with_tif.png")
```



## Fine-tuning figure size and gaps

### Exercises

- save the figure in different sizes 
- introduce gap with # into layout, also need to define width of gap as say 0.05
- change position of scalebar and scalebar legend

```{r}
#| echo=TRUE, eval=TRUE

#no gap in layout
layout1 <- "AB"

#assemble multipanel figure based on layout
Figure_scalebars <- panel_NOS2d_HCR + panel_NIT_HCR +
  plot_layout(design = layout1, widths = c(1, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_scalebars_no_gap.png", 
  limitsize = FALSE,
  units = c("px"), Figure_scalebars, 
  width = 1700, height = 940,
  bg = "white"
  )

image_read("../manuscript/figures/Figure_scalebars_no_gap.png")

#introduce gap in layout
layout2 <- "A#B"

#assemble multipanel figure based on layout
Figure_scalebars <- panel_NOS2d_HCR + panel_NIT_HCR +
  plot_layout(design = layout2, widths = c(1, 0.03, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_scalebars_gap.png", 
  limitsize = FALSE,
  units = c("px"), Figure_scalebars, 
  width = 1700, height = 940,
  bg = "white"
  )

image_read("../manuscript/figures/Figure_scalebars_gap.png")

```

## More complex figure layouts

```{r}
#| echo=TRUE, eval=TRUE

#read images and make annotated panel
panel_Platy <- ggdraw() + draw_image(readPNG("../analysis/pictures/Platynereis_SEM_inverted_nolabel.png"))
panel_NOS <- ggdraw() + draw_image(readPNG("../analysis/pictures/HCR-IHC_51_AP_NOS_actub_56um.png"))
panel_FVRI <- ggdraw() + draw_image(readPNG("../analysis/pictures/FVRIa_rhoPhall_31h_200um.png"))
panel_Jose <- ggdraw() + draw_image(readPNG("../analysis/pictures/plot_Jose1b.png"))
panel_INNOS <- ggdraw() + draw_image(readPNG("../analysis/pictures/INNOS_synapses.png"))
panel_NIT <- ggdraw() + draw_image(readPNG("../analysis/pictures/IHC_55_AP_NITGC2_actub_61um.png"))
panel_DAF <- ggdraw() + draw_image(readPNG("../analysis/pictures/DAFFM.png"))
panel_model <- ggdraw() + draw_image(readPNG("../analysis/pictures/Magnitude_model_cPRC.png"))

#introduce gap in layout
layout <- "
AAAABBBBCCCC
AAAABBBBDDDD
############
EEEFFFGGGHHH
EEEFFFGGGHHH
"
```

## More complex figure layouts

```{r}
#| echo=TRUE, eval=TRUE

#assemble multipanel figure based on layout
Figure_complex <- panel_Platy + panel_FVRI +  panel_NOS + 
  panel_NIT +
  panel_INNOS + panel_Jose + panel_DAF +
  panel_model +
  plot_layout(design = layout, heights = c(1, 1, 0.05, 1, 1)) +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 12, face='plain'))

#save figure as png
ggsave(
  "../manuscript/figures/Figure_complex.png",
  units = c("px"), Figure_complex, 
  width = 2600, height = 1700, bg = "white"
  )
```

```{r}
#| echo=FALSE, eval=TRUE
image_read("../manuscript/figures/Figure_complex.png")
```



## Vector graphics and drawings

<br>

- https://scidraw.io/ for high-quality CC-BY drawings
- Inkscape (free) or Illustrator (license) for vector graphics
- export as image, import into R workflow

## Image saved with a defined resolution (dpi)


```{r}
#| echo=TRUE, eval=TRUE

ggsave(
  "../manuscript/figures/Figure_complex_300dpi.png",
  units = c("cm"), Figure_complex, 
  width = 22, height = 13, dpi = 300, bg = "white"
  )
```

## Part 5 - Writing papers and reports in Quarto/Rmarkdown

-   Powerful and versatile text editing with simple Markdown syntax or visual editor (similar to Word)

-   Easy insertion and formatting of references from the web or a .bib file

-   Supports equations, tables, code blocks

-   Directly insert your figures generated by your scripts in the same project

-   Can 'knit' into html, pdf or docx formats

-   -\> Open manuscript/Manuscript.qmd

## Quarto - Documentation

<br>

-   Quarto enables you to weave together content and executable code into a finished presentation.
-   To learn more about Quarto presentations see <https://quarto.org/docs/presentations/>.

## The YAML header

- A YAML header contains YAML arguments, such as “title”, “author”, and “output”, demarcated by three dashes (-) on either end.
- When you create a new Quarto doc or presentation, it is created with a short YAML

```{r}
#| echo=TRUE, eval=FALSE
---
title: "Untitled"
format: html
---
  
```

- There is a more complex YAML in manuscript/Manuscript.qmd

```{r}
#| echo=TRUE, eval=FALSE

---
title: "Paper or report template"
subtitle: |
  \raggedright  Author 1^1,2,\*^ , Author 2^1,2^, Author 3^3^, Author 4E^4^ \newline<br>^1^Heidelberg University, Centre for Organismal Studies (COS), 69120 Heidelberg, Germany \newline<br>^2^Affiliation 2 \newline<br>^3^Affiliation 3 \newline<br>^4^Affiliation 4\newline<br>  ^\*^Correspondence: xy@cos.uni-heidelberg.de
mainfont: Arial
monofont: DejaVu Sans Mono #Times New Roman
fontsize: 11pt
linestretch: 1.2
linkcolor: blue
documentclass: article
crossref:
  fig-title: Figure     # (default is "Figure")
max-width: 100%
format:
  html: 
    embed-resources: true
  pdf:
    pdf-engine: xelatex
    number-sections: false
    margin-left: 0.8in
    margin-right: 0.8in
    margin-top: 0.8in
    margin-bottom: 0.8in
    toc: true
    keep-tex: true
    include-in-header:
      text: |
        \usepackage{lineno}
    include-before-body:
      text: |
        \linenumbers
bibliography: references.bib #add bibliography in this file
csl: elife.csl #change according to journal
---
  
```


## Simple syntax

- [This is]{.underline} 
- A **Quarto** *document.* 
- Quarto uses a simple ^Markdown^ formatting syntax for authoring HTML, PDF, and MS Word or .odt documents. - Here is some **text in bold** *italic* [underline]{.underline} and ^superscript^.


## Inserting references

<br>

-   In Visual mode, go to 'Insert' -\> 'Citation'
-   search for reference on pubmed etc.
-   'Insert' will add the ref to themanuscript/ bibliograpy.bib file (needs to be defined in the Yaml header)
-   in our doc, references will be formatted in the eLife style (defined in the Yaml header under: csl: elife.csl)
-   The elife.csl file is saved in the manuscript folder.
-   For a different format, download the respective .csl file (e.g., from the Zotero style repository <https://www.zotero.org/styles>)
-   in 'Source' mode, you can directly insert the reference with [@ref_id] (preferred, faster method)

## Inserting references

<br>

-   you can also add new refs to your .bib file with the command-line command:

:\$ curl -LH "Accept: application/x-bibtex" https://doi.org/10.7554/eLife.34550 \>\> ./references.bib <br>

::: callout-warning
-   need to add references.bib to the YAML header as bibliography: references.bib
-   also define bibliography style in the YAML with csl: elife.csl #add .csl according to journal
- if you use the command line, use >> and not > otherwise you will overwrite your file!
:::

## Inserting figures

<br>

-   we can now insert the figures we generated previously and saved under /manuscript/figures or /manuscript/figure_supplements

-   Figure title and legend can also be edited, as well as width

```{r, out.width = "100%", fig.cap="**Figure 1. A figure** (A) A nice picture. (B) legend.  (C) <br> (D) " }
#| echo: true 

knitr::include_graphics("../manuscript/figures/Figure1.png")
```

## Adding equations

<br>

- Equations can also be inserted, Insert -\> Display Math:

$$
\bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{n}
$$
## Sourcing code and working with variable

```{r}
#| eval: true
source("../analysis/scripts/statistics_for_paper.R")
```

-   We can use the 'r variable' syntax to add variables calculated in the sourced code directly to the text
-   This way if the underlying dataset changes, we just reprocess a calculation and insert the result directly into our manuscript
- the script is sourced and it runs but the output is not included in the knitted output. But we can access the variables defined in the sourced script simply by adding \` r var_name \` between \` backticks, in this case max_PRC value is `r max_PRC` (now this number comes from our sourced script).


## Tables

```{r}
#| echo=TRUE, eval=TRUE

#render built-in iris table with tinytable
tinytable::tt(head(iris))

#create some data
mydata <- tibble(
  gene = c("A", "B"),
  expression = c(1.1, 0.4)
  )

#render table
tt(mydata)

#read data
resources_table <- readxl::read_xls("../analysis/data/Key_resource_table.xls")

tt(
  resources_table, caption = "Key Resources Table", 
  theme = "grid", width = 1
  )

```


## Part 6 - Collaborative code and paper writing with Rstudio and git

<br>

-   git is an open source program and protocol for version control
- several online platforms were built to make code sharing with git easier
- GitHub www.github.com is one such platform
- GitHub is owned by Microsoft since 2018
- developers can have public and private repositories
- can share repositories privately with collaborators
- integrates well with Rstudio


## The workflow

-   Create a new project or clone a template project on GitHub
-   In Rstudio, New Project -\> Version control -\> add GitHub repo URL and save locally
-   Change the code
-   You can 'commit' and then 'push' changes to GitHub
-   Your collaborators can be added on GitHub
-   Collaborators can 'pull' to their own computer and 'push' their own changes
-   If two developers push changes to the same repo, this can lead to conflict
-   This can be managed by starting new 'branches'
-   Branches can be 'merged' to the original 'master' branch
-   A collaborator can issue a 'pull request' to merge their branch to the master

## Collaborations - sharing and commenting

<br>

-   Adding comments directly to the Quarto file with \<!--# my comment --> (these will not be knitted to the output)
- share as .docx and ask collaborators to use track changes (then why did we take this course...)
- collaborate on the same GitHub repository, use branches and pull requests (only makes sense if the collaborators are very involved)
- in principle you could use an Rproject for data, code and figures, and write text+refs on Gdocs+Paperpile or Overleaf+bib
- share commentable html through your github or other website
- we will use 'https://hypothes.is/' to add commenting functionality to an html 
- you need an account (easy and free)
- we use a https://github.com/hypothesis/client script that is sourced at the end of the quarto file by \<script src="hypothes.is/embed.js" async></script> to make this work

::: callout-warning
- you need to host the html on a website for sharing
:::

## Publication - GitHub and Zenodo integration

<br>

- GitHub is not a publishing platform 
- The owner could delete or make private the entire repo one day after publishing
- To stably publish your code and source data repository with a DOI ( globally unique and persistent identifier), you can use Zenodo
- Launched in 2013 by CERN
- Upload and link your GitHub repo to Zenodo

![](images/zenodo-gradient-1000.png){.absolute top="260" left="550" height="100"}


## Citation

<br>

- add/update a citation (CITATION.cff) file to your repo
- include the Zenodo DOI
- also cite your Zenodo repository in your manuscript
- see [example](https://zenodo.org/records/10978753)
- Make releases of your GitHub repo (e.g. initial submission, version of record), see [example](https://github.com/JekelyLab/Thiel_Yanez_Nematostella/tree/v3.0.0)
- The releases will be shown on Zenodo and are citeable

## Add README file to your repository

<br>

- open the README file (README.Rmd)
- README.md is generated from README.Rmd. Please edit that file
- modify the file according to your project
- add citation of the Zenodo repo with DOI
- add License, Acknowledgements etc.


